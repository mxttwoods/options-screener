{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa454026",
   "metadata": {},
   "source": [
    "# BTO Call/Put Screener (Multi-Horizon)\n",
    "\n",
    "**Purpose**: Screen liquid U.S. equities and score buy-to-open (BTO) call and put candidates across three time horizons, producing ranked leaderboards and a diversified portfolio.\n",
    "\n",
    "**What this produces**\n",
    "\n",
    "1. Dynamic universe discovery via equity screener or manual ticker override.\n",
    "2. Underlying trend, valuation, and volatility feature set per ticker.\n",
    "3. Option chain analysis across short (7--30 DTE), medium (31--120 DTE), and LEAPS (250--760 DTE) horizons.\n",
    "4. IV-first scoring model with profitability, alignment, and liquidity factors.\n",
    "5. Cross-horizon leaderboards and trifecta ideas (setups that persist across all three horizons).\n",
    "6. Correlation and beta-weighted diversified portfolio construction.\n",
    "\n",
    "**Important**: This notebook is for research and education only. It is not investment advice. Validate assumptions, liquidity, and event risk before trading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a2a2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 21 (2890437309.py, line 22)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(x)\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after function definition on line 21\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from yfinance import EquityQuery\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "try:\n",
    " from IPython.display import display, Markdown\n",
    "except ImportError:\n",
    "\n",
    " def display(x):\n",
    " print(x)\n",
    "\n",
    " class Markdown(str):\n",
    " pass\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 220)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "\n",
    "PLOTLY_RENDERER = os.getenv(\"PLOTLY_RENDERER\", \"notebook_connected\")\n",
    "pio.renderers.default = PLOTLY_RENDERER\n",
    "\n",
    "# ── Display helpers ──\n",
    "try:\n",
    " import jinja2\n",
    " HAS_JINJA = True\n",
    "except Exception:\n",
    " HAS_JINJA = False\n",
    "\n",
    "REPORT_TEMPLATE = go.layout.Template(\n",
    " layout=go.Layout(\n",
    " font=dict(family=\"Times New Roman\", size=14, color=\"#111827\"),\n",
    " title=dict(font=dict(size=20)),\n",
    " paper_bgcolor=\"white\",\n",
    " plot_bgcolor=\"white\",\n",
    " xaxis=dict(showgrid=True, gridcolor=\"#E5E7EB\", zeroline=False,\n",
    " linecolor=\"#111827\", mirror=True),\n",
    " yaxis=dict(showgrid=True, gridcolor=\"#E5E7EB\", zeroline=False,\n",
    " linecolor=\"#111827\", mirror=True),\n",
    " legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    " margin=dict(l=60, r=30, t=70, b=50),\n",
    " )\n",
    ")\n",
    "pio.templates[\"report\"] = REPORT_TEMPLATE\n",
    "pio.templates.default = \"report\"\n",
    "\n",
    "COLOR_DISCRETE = [\"#1F3A5F\", \"#4C6E91\", \"#8B9BB4\", \"#B0533C\", \"#7A3E3E\", \"#556B2F\"]\n",
    "COLOR_CONTINUOUS = [\"#f7fbff\", \"#c6dbef\", \"#6baed6\", \"#2171b5\", \"#08306b\"]\n",
    "\n",
    "\n",
    "def display_table(df, caption=\"\", format_dict=None):\n",
    " \"\"\"Display a styled DataFrame with optional formatting.\"\"\"\n",
    " styler = df.style\n",
    " if format_dict:\n",
    " styler = styler.format(format_dict, na_rep=\"--\")\n",
    " if caption:\n",
    " styler = styler.set_caption(caption)\n",
    " display(styler)\n",
    "\n",
    "\n",
    "def show_figure(fig):\n",
    " \"\"\"Show a plotly figure with error handling.\"\"\"\n",
    " try:\n",
    " fig.show()\n",
    " except Exception as e:\n",
    " print(f\" [plot error] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ac2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run configuration\n",
    "USE_SCREEN = os.getenv(\"USE_SCREEN\", \"1\") == \"1\"\n",
    "TICKER_OVERRIDE = [\n",
    "    t.strip().upper() for t in os.getenv(\"TICKER_OVERRIDE\", \"\").split(\",\") if t.strip()\n",
    "]\n",
    "CONVICTION_TICKERS = [\n",
    "    t.strip().upper()\n",
    "    for t in os.getenv(\"CONVICTION_TICKERS\", \"\").split(\",\")\n",
    "    if t.strip()\n",
    "]\n",
    "\n",
    "MAX_TICKERS = int(os.getenv(\"MAX_TICKERS\", \"35\"))\n",
    "RATE_LIMIT_SLEEP = float(os.getenv(\"RATE_LIMIT_SLEEP\", \"0.30\"))\n",
    "RISK_FREE_RATE = float(os.getenv(\"RISK_FREE_RATE\", \"0.043\"))\n",
    "HISTORY_PERIOD = os.getenv(\"HISTORY_PERIOD\", \"1y\")\n",
    "\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\", \"outputs\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "RUN_STAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "SCREEN_PARAMS = dict(\n",
    "    max_price=350.0,\n",
    "    min_market_cap=2_000_000_000,\n",
    "    min_roe=0.08,\n",
    "    min_rev_growth=0.00,\n",
    "    max_pe=45.0,\n",
    "    max_ps=12.0,\n",
    "    min_beta=0.6,\n",
    "    max_beta=2.8,\n",
    "    min_inst_held=0.35,\n",
    "    size=90,\n",
    "    sort_by=\"eodvolume\",\n",
    ")\n",
    "\n",
    "HORIZONS = {\n",
    "    \"short\": {\"min_dte\": 7, \"max_dte\": 30, \"target_dte\": 21},\n",
    "    \"medium\": {\"min_dte\": 31, \"max_dte\": 120, \"target_dte\": 60},\n",
    "    \"leaps\": {\"min_dte\": 250, \"max_dte\": 760, \"target_dte\": 420},\n",
    "}\n",
    "\n",
    "MAX_EXP_PER_HORIZON = 2\n",
    "MAX_CONTRACTS_PER_EXP = 40\n",
    "\n",
    "OPTION_SIDE_CONFIG = {\n",
    "    \"call\": {\n",
    "        \"short\": {\"min_moneyness\": 0.95, \"max_moneyness\": 1.08},\n",
    "        \"medium\": {\"min_moneyness\": 0.90, \"max_moneyness\": 1.10},\n",
    "        \"leaps\": {\"min_moneyness\": 0.75, \"max_moneyness\": 1.08},\n",
    "    },\n",
    "    \"put\": {\n",
    "        \"short\": {\"min_moneyness\": 0.92, \"max_moneyness\": 1.08},\n",
    "        \"medium\": {\"min_moneyness\": 0.88, \"max_moneyness\": 1.12},\n",
    "        \"leaps\": {\"min_moneyness\": 0.80, \"max_moneyness\": 1.15},\n",
    "    },\n",
    "}\n",
    "\n",
    "SCENARIO_MOVES = {\n",
    "    \"short\": {\"bull\": 0.06, \"base\": 0.00, \"bear\": -0.06},\n",
    "    \"medium\": {\"bull\": 0.12, \"base\": 0.02, \"bear\": -0.12},\n",
    "    \"leaps\": {\"bull\": 0.35, \"base\": 0.10, \"bear\": -0.25},\n",
    "}\n",
    "\n",
    "LIQUIDITY_FILTER = True\n",
    "MIN_OPEN_INTEREST = int(os.getenv(\"MIN_OPEN_INTEREST\", \"50\"))\n",
    "MIN_VOLUME = int(os.getenv(\"MIN_VOLUME\", \"10\"))\n",
    "MAX_SPREAD_PCT = float(os.getenv(\"MAX_SPREAD_PCT\", \"0.35\"))\n",
    "MIN_PREMIUM = float(os.getenv(\"MIN_PREMIUM\", \"0.25\"))\n",
    "MAX_PREMIUM = float(os.getenv(\"MAX_PREMIUM\", \"70.0\"))\n",
    "\n",
    "MIN_UNDERLYING_AVG_VOLUME = int(os.getenv(\"MIN_UNDERLYING_AVG_VOLUME\", \"800000\"))\n",
    "\n",
    "HORIZON_SCORE_WEIGHTS = {\n",
    "    \"short\": {\n",
    "        \"iv_value\": 0.15,\n",
    "        \"expected\": 0.24,\n",
    "        \"rr\": 0.20,\n",
    "        \"pop\": 0.08,\n",
    "        \"alignment\": 0.18,\n",
    "        \"liquidity\": 0.15,\n",
    "        \"conviction\": 0.00,\n",
    "    },\n",
    "    \"medium\": {\n",
    "        \"iv_value\": 0.16,\n",
    "        \"expected\": 0.22,\n",
    "        \"rr\": 0.16,\n",
    "        \"pop\": 0.12,\n",
    "        \"alignment\": 0.18,\n",
    "        \"liquidity\": 0.10,\n",
    "        \"conviction\": 0.06,\n",
    "    },\n",
    "    \"leaps\": {\n",
    "        \"iv_value\": 0.18,\n",
    "        \"expected\": 0.15,\n",
    "        \"rr\": 0.08,\n",
    "        \"pop\": 0.12,\n",
    "        \"alignment\": 0.20,\n",
    "        \"liquidity\": 0.08,\n",
    "        \"conviction\": 0.19,\n",
    "    },\n",
    "}\n",
    "\n",
    "TRIFECTA_WEIGHTS = {\"short\": 0.25, \"medium\": 0.35, \"leaps\": 0.40}\n",
    "TOP_PER_BUCKET = int(os.getenv(\"TOP_PER_BUCKET\", \"8\"))\n",
    "\n",
    "summary_config = pd.DataFrame(\n",
    "    {\n",
    "        \"Parameter\": [\n",
    "            \"USE_SCREEN\",\n",
    "            \"MAX_TICKERS\",\n",
    "            \"RATE_LIMIT_SLEEP\",\n",
    "            \"RISK_FREE_RATE\",\n",
    "            \"HORIZONS\",\n",
    "            \"LIQUIDITY_FILTER\",\n",
    "            \"MIN_OPEN_INTEREST\",\n",
    "            \"MIN_VOLUME\",\n",
    "            \"MAX_SPREAD_PCT\",\n",
    "            \"MIN_PREMIUM\",\n",
    "            \"MAX_PREMIUM\",\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            USE_SCREEN,\n",
    "            MAX_TICKERS,\n",
    "            RATE_LIMIT_SLEEP,\n",
    "            RISK_FREE_RATE,\n",
    "            str(HORIZONS),\n",
    "            LIQUIDITY_FILTER,\n",
    "            MIN_OPEN_INTEREST,\n",
    "            MIN_VOLUME,\n",
    "            MAX_SPREAD_PCT,\n",
    "            MIN_PREMIUM,\n",
    "            MAX_PREMIUM,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "display(summary_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ae05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_float(value, default=np.nan):\n",
    " try:\n",
    " if value is None:\n",
    " return default\n",
    " out = float(value)\n",
    " if np.isnan(out):\n",
    " return default\n",
    " return out\n",
    " except Exception:\n",
    " return default\n",
    "\n",
    "\n",
    "def clamp(value, low, high):\n",
    " return max(low, min(high, value))\n",
    "\n",
    "\n",
    "def norm_cdf(x: float) -> float:\n",
    " return 0.5 * (1 + math.erf(x / math.sqrt(2)))\n",
    "\n",
    "\n",
    "def pct_rank(series: pd.Series, higher_better: bool = True, fill=0.5) -> pd.Series:\n",
    " s = pd.to_numeric(series, errors=\"coerce\")\n",
    " rank = s.rank(pct=True, ascending=not higher_better)\n",
    " return rank.fillna(fill)\n",
    "\n",
    "\n",
    "def weighted_average(values: Dict[str, float], weights: Dict[str, float]) -> float:\n",
    " total_weight = 0.0\n",
    " total = 0.0\n",
    " for key, weight in weights.items():\n",
    " value = safe_float(values.get(key), np.nan)\n",
    " if np.isnan(value):\n",
    " continue\n",
    " total += value * weight\n",
    " total_weight += weight\n",
    " if total_weight <= 0:\n",
    " return np.nan\n",
    " return total / total_weight\n",
    "\n",
    "\n",
    "def compute_rsi(closes: pd.Series, window: int = 14) -> Optional[float]:\n",
    " if closes is None or len(closes) < window + 2:\n",
    " return None\n",
    " delta = closes.diff()\n",
    " gain = delta.clip(lower=0)\n",
    " loss = -delta.clip(upper=0)\n",
    " avg_gain = gain.rolling(window).mean().iloc[-1]\n",
    " avg_loss = loss.rolling(window).mean().iloc[-1]\n",
    " if avg_loss is None or pd.isna(avg_loss):\n",
    " return None\n",
    " if avg_loss == 0:\n",
    " return 100.0\n",
    " rs = avg_gain / avg_loss\n",
    " return float(100 - (100 / (1 + rs)))\n",
    "\n",
    "\n",
    "def bsm_prob_above(\n",
    " spot: float, level: float, iv: float, dte: int, r: float = RISK_FREE_RATE\n",
    ") -> Optional[float]:\n",
    " if spot <= 0 or level <= 0 or iv <= 0 or dte <= 0:\n",
    " return None\n",
    " t = dte / 365.0\n",
    " try:\n",
    " d2 = (math.log(spot / level) + (r - 0.5 * iv**2) * t) / (iv * math.sqrt(t))\n",
    " return float(norm_cdf(d2))\n",
    " except Exception:\n",
    " return None\n",
    "\n",
    "\n",
    "def bsm_prob_below(\n",
    " spot: float, level: float, iv: float, dte: int, r: float = RISK_FREE_RATE\n",
    ") -> Optional[float]:\n",
    " p_above = bsm_prob_above(spot, level, iv, dte, r=r)\n",
    " if p_above is None:\n",
    " return None\n",
    " return float(1.0 - p_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c38fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_for_candidates(\n",
    " max_price: float = 350.0,\n",
    " min_market_cap: float = 2_000_000_000,\n",
    " min_roe: float = 0.08,\n",
    " min_rev_growth: float = 0.0,\n",
    " max_pe: float = 45.0,\n",
    " max_ps: float = 12.0,\n",
    " min_beta: float = 0.6,\n",
    " max_beta: float = 2.8,\n",
    " min_inst_held: float = 0.35,\n",
    " size: int = 80,\n",
    " sort_by: str = \"eodvolume\",\n",
    ") -> List[str]:\n",
    " sectors = [\n",
    " \"Communication Services\",\n",
    " \"Consumer Cyclical\",\n",
    " \"Consumer Defensive\",\n",
    " \"Energy\",\n",
    " \"Financial Services\",\n",
    " \"Healthcare\",\n",
    " \"Industrials\",\n",
    " \"Technology\",\n",
    " \"Utilities\",\n",
    " ]\n",
    "\n",
    " filters = [\n",
    " EquityQuery(\"eq\", [\"region\", \"us\"]),\n",
    " EquityQuery(\"is-in\", [\"exchange\", \"NMS\", \"NYQ\"]),\n",
    " EquityQuery(\"btwn\", [\"intradaymarketcap\", min_market_cap, 4_000_000_000_000]),\n",
    " EquityQuery(\"btwn\", [\"intradayprice\", 8, max_price]),\n",
    " EquityQuery(\"btwn\", [\"peratio.lasttwelvemonths\", 0, max_pe]),\n",
    " EquityQuery(\"lt\", [\"lastclosemarketcaptotalrevenue.lasttwelvemonths\", max_ps]),\n",
    " EquityQuery(\"gte\", [\"returnonequity.lasttwelvemonths\", min_roe]),\n",
    " EquityQuery(\"gte\", [\"totalrevenues1yrgrowth.lasttwelvemonths\", min_rev_growth]),\n",
    " EquityQuery(\"gte\", [\"pctheldinst\", min_inst_held]),\n",
    " EquityQuery(\"btwn\", [\"beta\", min_beta, max_beta]),\n",
    " EquityQuery(\"is-in\", [\"sector\"] + sectors),\n",
    " ]\n",
    "\n",
    " query = EquityQuery(\"and\", filters)\n",
    " response = yf.screen(query, size=size, sortField=sort_by, sortAsc=False)\n",
    "\n",
    " quotes = []\n",
    " if response:\n",
    " if \"quotes\" in response:\n",
    " quotes = response.get(\"quotes\", [])\n",
    " elif \"finance\" in response:\n",
    " result = response.get(\"finance\", {}).get(\"result\", [])\n",
    " if result:\n",
    " quotes = result[0].get(\"quotes\", [])\n",
    "\n",
    " return [row.get(\"symbol\") for row in quotes if row.get(\"symbol\")]\n",
    "\n",
    "\n",
    "def get_spot(ticker: str) -> Optional[float]:\n",
    " try:\n",
    " t = yf.Ticker(ticker)\n",
    " time.sleep(RATE_LIMIT_SLEEP)\n",
    " hist = t.history(period=\"1d\")\n",
    " if not hist.empty and \"Close\" in hist.columns:\n",
    " return float(hist[\"Close\"].iloc[-1])\n",
    "\n",
    " time.sleep(RATE_LIMIT_SLEEP)\n",
    " fast = t.fast_info or {}\n",
    " price = fast.get(\"lastPrice\") or fast.get(\"regularMarketPrice\")\n",
    " if price:\n",
    " return float(price)\n",
    "\n",
    " time.sleep(RATE_LIMIT_SLEEP)\n",
    " info = t.info or {}\n",
    " price = info.get(\"regularMarketPrice\") or info.get(\"currentPrice\")\n",
    " if price:\n",
    " return float(price)\n",
    " except Exception:\n",
    " return None\n",
    " return None\n",
    "\n",
    "\n",
    "def fetch_fundamentals(ticker: str) -> dict:\n",
    " t = yf.Ticker(ticker)\n",
    " time.sleep(RATE_LIMIT_SLEEP)\n",
    "\n",
    " info = {}\n",
    " fast = {}\n",
    " try:\n",
    " info = t.info or {}\n",
    " except Exception:\n",
    " info = {}\n",
    " try:\n",
    " fast = t.fast_info or {}\n",
    " except Exception:\n",
    " fast = {}\n",
    "\n",
    " return {\n",
    " \"ticker\": ticker,\n",
    " \"market_cap\": safe_float(info.get(\"marketCap\") or fast.get(\"marketCap\")),\n",
    " \"beta\": safe_float(info.get(\"beta\")),\n",
    " \"pe\": safe_float(info.get(\"forwardPE\") or info.get(\"trailingPE\")),\n",
    " \"ps\": safe_float(info.get(\"priceToSalesTrailing12Months\")),\n",
    " \"roe\": safe_float(info.get(\"returnOnEquity\")),\n",
    " \"rev_growth\": safe_float(info.get(\"revenueGrowth\")),\n",
    " \"profit_margin\": safe_float(info.get(\"profitMargins\")),\n",
    " \"operating_margin\": safe_float(info.get(\"operatingMargins\")),\n",
    " \"debt_to_equity\": safe_float(info.get(\"debtToEquity\")),\n",
    " \"current_ratio\": safe_float(info.get(\"currentRatio\")),\n",
    " \"avg_volume_3m\": safe_float(\n",
    " info.get(\"averageVolume\") or info.get(\"averageDailyVolume3Month\")\n",
    " ),\n",
    " \"inst_held_pct\": safe_float(info.get(\"heldPercentInstitutions\")),\n",
    " \"sector\": info.get(\"sector\"),\n",
    " \"industry\": info.get(\"industry\"),\n",
    " }\n",
    "\n",
    "\n",
    "def fetch_history(ticker: str, period: str = HISTORY_PERIOD) -> pd.DataFrame:\n",
    " try:\n",
    " t = yf.Ticker(ticker)\n",
    " time.sleep(RATE_LIMIT_SLEEP)\n",
    " hist = t.history(period=period)\n",
    " if hist is None:\n",
    " return pd.DataFrame()\n",
    " return hist\n",
    " except Exception:\n",
    " return pd.DataFrame()\n",
    "\n",
    "\n",
    "def compute_realized_vol(log_returns: pd.Series, window: int = 30) -> Optional[float]:\n",
    " if log_returns is None or len(log_returns) < window:\n",
    " return None\n",
    " return float(log_returns.iloc[-window:].std() * math.sqrt(252))\n",
    "\n",
    "\n",
    "def _score_metric(value, bands):\n",
    " if value is None or pd.isna(value):\n",
    " return None\n",
    " for threshold, score, direction in bands:\n",
    " if direction == \"le\" and value <= threshold:\n",
    " return score\n",
    " if direction == \"ge\" and value >= threshold:\n",
    " return score\n",
    " return bands[-1][1]\n",
    "\n",
    "\n",
    "def compute_value_score(fund: dict) -> Optional[float]:\n",
    " pe = fund.get(\"pe\")\n",
    " ps = fund.get(\"ps\")\n",
    " roe = fund.get(\"roe\")\n",
    " rev_growth = fund.get(\"rev_growth\")\n",
    " margin = fund.get(\"profit_margin\")\n",
    "\n",
    " metrics = {\n",
    " \"pe\": _score_metric(\n",
    " pe,\n",
    " [\n",
    " (12, 92, \"le\"),\n",
    " (18, 80, \"le\"),\n",
    " (25, 65, \"le\"),\n",
    " (35, 45, \"le\"),\n",
    " (1e9, 25, \"le\"),\n",
    " ],\n",
    " ),\n",
    " \"ps\": _score_metric(\n",
    " ps,\n",
    " [\n",
    " (2.0, 90, \"le\"),\n",
    " (4.0, 75, \"le\"),\n",
    " (7.0, 58, \"le\"),\n",
    " (12.0, 40, \"le\"),\n",
    " (1e9, 20, \"le\"),\n",
    " ],\n",
    " ),\n",
    " \"roe\": _score_metric(\n",
    " roe,\n",
    " [\n",
    " (0.30, 92, \"ge\"),\n",
    " (0.20, 80, \"ge\"),\n",
    " (0.12, 65, \"ge\"),\n",
    " (0.08, 50, \"ge\"),\n",
    " (-1e9, 25, \"ge\"),\n",
    " ],\n",
    " ),\n",
    " \"rev_growth\": _score_metric(\n",
    " rev_growth,\n",
    " [\n",
    " (0.25, 90, \"ge\"),\n",
    " (0.12, 78, \"ge\"),\n",
    " (0.05, 62, \"ge\"),\n",
    " (0.00, 48, \"ge\"),\n",
    " (-1e9, 30, \"ge\"),\n",
    " ],\n",
    " ),\n",
    " \"margin\": _score_metric(\n",
    " margin,\n",
    " [\n",
    " (0.30, 88, \"ge\"),\n",
    " (0.20, 74, \"ge\"),\n",
    " (0.10, 58, \"ge\"),\n",
    " (0.00, 40, \"ge\"),\n",
    " (-1e9, 20, \"ge\"),\n",
    " ],\n",
    " ),\n",
    " }\n",
    "\n",
    " vals = [v for v in metrics.values() if v is not None]\n",
    " if not vals:\n",
    " return None\n",
    " return float(np.mean(vals))\n",
    "\n",
    "\n",
    "def compute_underlying_features(ticker: str) -> Optional[dict]:\n",
    " fund = fetch_fundamentals(ticker)\n",
    " spot = get_spot(ticker)\n",
    " if spot is None or spot <= 0:\n",
    " return None\n",
    "\n",
    " hist = fetch_history(ticker, period=HISTORY_PERIOD)\n",
    " if hist.empty or \"Close\" not in hist.columns:\n",
    " return None\n",
    "\n",
    " closes = hist[\"Close\"].dropna()\n",
    " if len(closes) < 80:\n",
    " return None\n",
    "\n",
    " returns = closes.pct_change().dropna()\n",
    " log_returns = np.log(closes / closes.shift(1)).dropna()\n",
    "\n",
    " ma_50 = closes.rolling(50).mean().iloc[-1] if len(closes) >= 50 else np.nan\n",
    " ma_200 = closes.rolling(200).mean().iloc[-1] if len(closes) >= 200 else np.nan\n",
    "\n",
    " ret_1m = (\n",
    " safe_float(closes.iloc[-1] / closes.iloc[-21] - 1, np.nan)\n",
    " if len(closes) > 21\n",
    " else np.nan\n",
    " )\n",
    " ret_3m = (\n",
    " safe_float(closes.iloc[-1] / closes.iloc[-63] - 1, np.nan)\n",
    " if len(closes) > 63\n",
    " else np.nan\n",
    " )\n",
    " ret_6m = (\n",
    " safe_float(closes.iloc[-1] / closes.iloc[-126] - 1, np.nan)\n",
    " if len(closes) > 126\n",
    " else np.nan\n",
    " )\n",
    "\n",
    " rsi_14 = compute_rsi(closes, window=14)\n",
    " hv_30 = compute_realized_vol(log_returns, 30)\n",
    " hv_60 = compute_realized_vol(log_returns, 60)\n",
    "\n",
    " rolling_hv = log_returns.rolling(30).std() * math.sqrt(252)\n",
    " rolling_hv = rolling_hv.dropna()\n",
    " iv_rank_proxy = np.nan\n",
    " iv_percentile_proxy = np.nan\n",
    " if len(rolling_hv) >= 40:\n",
    " current_hv = float(rolling_hv.iloc[-1])\n",
    " hv_low = float(rolling_hv.min())\n",
    " hv_high = float(rolling_hv.max())\n",
    " hv_range = hv_high - hv_low\n",
    " if hv_range > 0:\n",
    " iv_rank_proxy = (current_hv - hv_low) / hv_range * 100\n",
    " iv_percentile_proxy = float(\n",
    " (rolling_hv < current_hv).sum() / len(rolling_hv) * 100\n",
    " )\n",
    "\n",
    " bull_flags = [\n",
    " 1 if spot > ma_50 else 0,\n",
    " 1 if spot > ma_200 else 0,\n",
    " 1 if ma_50 > ma_200 else 0,\n",
    " 1 if ret_1m > 0 else 0,\n",
    " 1 if ret_3m > 0 else 0,\n",
    " ]\n",
    " bear_flags = [\n",
    " 1 if spot < ma_50 else 0,\n",
    " 1 if spot < ma_200 else 0,\n",
    " 1 if ma_50 < ma_200 else 0,\n",
    " 1 if ret_1m < 0 else 0,\n",
    " 1 if ret_3m < 0 else 0,\n",
    " ]\n",
    " bull_signal = float(np.mean(bull_flags))\n",
    " bear_signal = float(np.mean(bear_flags))\n",
    "\n",
    " value_score = compute_value_score(fund)\n",
    " if value_score is None or pd.isna(value_score):\n",
    " value_score = 50.0\n",
    "\n",
    " conviction_bull = 0.70 * (bull_signal * 100) + 0.30 * value_score\n",
    " conviction_bear = 0.75 * (bear_signal * 100) + 0.25 * (100 - value_score)\n",
    "\n",
    " avg_vol = safe_float(fund.get(\"avg_volume_3m\"), np.nan)\n",
    " if not np.isnan(avg_vol) and avg_vol < MIN_UNDERLYING_AVG_VOLUME:\n",
    " return None\n",
    "\n",
    " return {\n",
    " \"ticker\": ticker,\n",
    " \"spot\": float(spot),\n",
    " \"sector\": fund.get(\"sector\"),\n",
    " \"industry\": fund.get(\"industry\"),\n",
    " \"market_cap\": fund.get(\"market_cap\"),\n",
    " \"beta\": fund.get(\"beta\"),\n",
    " \"pe\": fund.get(\"pe\"),\n",
    " \"ps\": fund.get(\"ps\"),\n",
    " \"roe\": fund.get(\"roe\"),\n",
    " \"rev_growth\": fund.get(\"rev_growth\"),\n",
    " \"profit_margin\": fund.get(\"profit_margin\"),\n",
    " \"avg_volume_3m\": fund.get(\"avg_volume_3m\"),\n",
    " \"inst_held_pct\": fund.get(\"inst_held_pct\"),\n",
    " \"ret_1m\": ret_1m,\n",
    " \"ret_3m\": ret_3m,\n",
    " \"ret_6m\": ret_6m,\n",
    " \"rsi_14\": rsi_14,\n",
    " \"hv_30\": hv_30,\n",
    " \"hv_60\": hv_60,\n",
    " \"iv_rank_proxy\": iv_rank_proxy,\n",
    " \"iv_percentile_proxy\": iv_percentile_proxy,\n",
    " \"bull_signal\": bull_signal,\n",
    " \"bear_signal\": bear_signal,\n",
    " \"value_score\": value_score,\n",
    " \"conviction_bull\": conviction_bull,\n",
    " \"conviction_bear\": conviction_bear,\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAIN_CACHE: Dict[tuple, tuple[pd.DataFrame, pd.DataFrame]] = {}\n",
    "\n",
    "\n",
    "def get_expirations(ticker: str) -> List[tuple[str, int]]:\n",
    " try:\n",
    " t = yf.Ticker(ticker)\n",
    " time.sleep(RATE_LIMIT_SLEEP)\n",
    " exp_dates = t.options\n",
    " if not exp_dates:\n",
    " return []\n",
    "\n",
    " today = datetime.now().date()\n",
    " out = []\n",
    " for exp_str in exp_dates:\n",
    " try:\n",
    " exp_date = datetime.strptime(exp_str, \"%Y-%m-%d\").date()\n",
    " dte = (exp_date - today).days\n",
    " if dte > 0:\n",
    " out.append((exp_str, dte))\n",
    " except ValueError:\n",
    " continue\n",
    " return sorted(out, key=lambda x: x[1])\n",
    " except Exception:\n",
    " return []\n",
    "\n",
    "\n",
    "def pick_horizon_expirations(\n",
    " expirations: List[tuple[str, int]], horizon: str\n",
    ") -> List[tuple[str, int]]:\n",
    " cfg = HORIZONS[horizon]\n",
    " pool = [e for e in expirations if cfg[\"min_dte\"] <= e[1] <= cfg[\"max_dte\"]]\n",
    " if not pool:\n",
    " return []\n",
    " target = cfg[\"target_dte\"]\n",
    " pool = sorted(pool, key=lambda x: abs(x[1] - target))\n",
    " return pool[:MAX_EXP_PER_HORIZON]\n",
    "\n",
    "\n",
    "def add_chain_columns(\n",
    " df: pd.DataFrame, ticker: str, exp_date: str, spot: float\n",
    ") -> pd.DataFrame:\n",
    " if df.empty:\n",
    " return df\n",
    "\n",
    " out = df.copy()\n",
    " exp_dt = datetime.strptime(exp_date, \"%Y-%m-%d\").date()\n",
    " dte = (exp_dt - datetime.now().date()).days\n",
    "\n",
    " out[\"ticker\"] = ticker\n",
    " out[\"expiration\"] = exp_date\n",
    " out[\"dte\"] = dte\n",
    " out[\"spot\"] = spot\n",
    " out[\"mid\"] = (out[\"bid\"] + out[\"ask\"]) / 2\n",
    " out.loc[out[\"mid\"] <= 0, \"mid\"] = out.get(\"lastPrice\")\n",
    " out[\"moneyness\"] = out[\"strike\"] / spot\n",
    " out[\"spread\"] = out[\"ask\"] - out[\"bid\"]\n",
    " out[\"spread_pct\"] = np.where(out[\"mid\"] > 0, out[\"spread\"] / out[\"mid\"], np.nan)\n",
    " return out\n",
    "\n",
    "\n",
    "def fetch_chain(\n",
    " ticker: str, exp_date: str, spot: float\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    " key = (ticker, exp_date)\n",
    " if key in CHAIN_CACHE:\n",
    " return CHAIN_CACHE[key]\n",
    "\n",
    " try:\n",
    " t = yf.Ticker(ticker)\n",
    " time.sleep(RATE_LIMIT_SLEEP)\n",
    " chain = t.option_chain(exp_date)\n",
    " calls = add_chain_columns(chain.calls, ticker, exp_date, spot)\n",
    " puts = add_chain_columns(chain.puts, ticker, exp_date, spot)\n",
    " CHAIN_CACHE[key] = (calls, puts)\n",
    " return calls, puts\n",
    " except Exception:\n",
    " empty = (pd.DataFrame(), pd.DataFrame())\n",
    " CHAIN_CACHE[key] = empty\n",
    " return empty\n",
    "\n",
    "\n",
    "def compute_prob_profit(\n",
    " side: str, spot: float, strike: float, premium: float, iv: float, dte: int\n",
    ") -> Optional[float]:\n",
    " if premium <= 0 or iv <= 0 or dte <= 0:\n",
    " return None\n",
    " if side == \"call\":\n",
    " breakeven = strike + premium\n",
    " return bsm_prob_above(spot, breakeven, iv, dte)\n",
    " breakeven = max(0.01, strike - premium)\n",
    " return bsm_prob_below(spot, breakeven, iv, dte)\n",
    "\n",
    "\n",
    "def scenario_probabilities(feature_row: dict) -> Dict[str, float]:\n",
    " bull_signal = safe_float(feature_row.get(\"bull_signal\"), 0.5)\n",
    " bear_signal = safe_float(feature_row.get(\"bear_signal\"), 0.5)\n",
    "\n",
    " bull = clamp(0.25 + 0.45 * (bull_signal - 0.5), 0.10, 0.80)\n",
    " bear = clamp(0.25 + 0.45 * (bear_signal - 0.5), 0.10, 0.80)\n",
    " base = max(0.10, 1.0 - bull - bear)\n",
    "\n",
    " total = bull + base + bear\n",
    " return {\"bull\": bull / total, \"base\": base / total, \"bear\": bear / total}\n",
    "\n",
    "\n",
    "def option_payoff(\n",
    " side: str, terminal_spot: float, strike: float, premium: float\n",
    ") -> float:\n",
    " if side == \"call\":\n",
    " return max(terminal_spot - strike, 0.0) - premium\n",
    " return max(strike - terminal_spot, 0.0) - premium\n",
    "\n",
    "\n",
    "def iv_value_score(\n",
    " iv: float, hv_30: float, iv_rank_proxy: float, iv_percentile_proxy: float\n",
    ") -> float:\n",
    " ratio = np.nan\n",
    " if (\n",
    " hv_30 is not None\n",
    " and not pd.isna(hv_30)\n",
    " and hv_30 > 0\n",
    " and iv is not None\n",
    " and not pd.isna(iv)\n",
    " ):\n",
    " ratio = iv / hv_30\n",
    "\n",
    " ratio_score = 45.0\n",
    " if not pd.isna(ratio):\n",
    " ratio_score = np.clip((1.45 - ratio) / 0.90 * 100, 0, 100)\n",
    "\n",
    " rank_score = np.clip(100 - safe_float(iv_rank_proxy, 50.0), 0, 100)\n",
    " pctile_score = np.clip(100 - safe_float(iv_percentile_proxy, 50.0), 0, 100)\n",
    "\n",
    " return float(0.50 * ratio_score + 0.25 * rank_score + 0.25 * pctile_score)\n",
    "\n",
    "\n",
    "def liquidity_score(open_interest: float, volume: float, spread_pct: float) -> float:\n",
    " oi = safe_float(open_interest, 0.0)\n",
    " vol = safe_float(volume, 0.0)\n",
    " spd = safe_float(spread_pct, np.nan)\n",
    "\n",
    " oi_score = np.clip(oi / 600 * 100, 0, 100)\n",
    " vol_score = np.clip(vol / 200 * 100, 0, 100)\n",
    " if pd.isna(spd):\n",
    " spread_score = 40\n",
    " else:\n",
    " spread_score = np.clip((0.40 - spd) / 0.35 * 100, 0, 100)\n",
    "\n",
    " return float(0.40 * oi_score + 0.25 * vol_score + 0.35 * spread_score)\n",
    "\n",
    "\n",
    "def expected_return_score(expected_return: float) -> float:\n",
    " return float(np.clip((expected_return + 0.40) / 2.40 * 100, 0, 100))\n",
    "\n",
    "\n",
    "def rr_score(rr_multiple: float) -> float:\n",
    " return float(np.clip(rr_multiple * 28, 0, 100))\n",
    "\n",
    "\n",
    "def evaluate_option_candidate(\n",
    " option_row: pd.Series, side: str, horizon: str, feature_row: dict\n",
    ") -> dict:\n",
    " spot = safe_float(option_row.get(\"spot\"), np.nan)\n",
    " strike = safe_float(option_row.get(\"strike\"), np.nan)\n",
    " premium = safe_float(option_row.get(\"mid\"), np.nan)\n",
    " dte = int(safe_float(option_row.get(\"dte\"), 0))\n",
    " iv = safe_float(option_row.get(\"impliedVolatility\"), np.nan)\n",
    "\n",
    " if (\n",
    " np.isnan(spot)\n",
    " or np.isnan(strike)\n",
    " or np.isnan(premium)\n",
    " or np.isnan(iv)\n",
    " or spot <= 0\n",
    " or strike <= 0\n",
    " or premium <= 0\n",
    " or iv <= 0\n",
    " or dte <= 0\n",
    " ):\n",
    " return {}\n",
    "\n",
    " horizon_moves = SCENARIO_MOVES[horizon]\n",
    " probs = scenario_probabilities(feature_row)\n",
    "\n",
    " scenario_returns = {}\n",
    " scenario_pnl = {}\n",
    " for key, move in horizon_moves.items():\n",
    " terminal_spot = spot * (1 + move)\n",
    " pnl = option_payoff(side, terminal_spot, strike, premium)\n",
    " scenario_pnl[key] = pnl\n",
    " scenario_returns[key] = pnl / premium\n",
    "\n",
    " expected_return = sum(\n",
    " probs[k] * scenario_returns[k] for k in [\"bear\", \"base\", \"bull\"]\n",
    " )\n",
    "\n",
    " directional_return = (\n",
    " scenario_returns[\"bull\"] if side == \"call\" else scenario_returns[\"bear\"]\n",
    " )\n",
    " adverse_return = (\n",
    " scenario_returns[\"bear\"] if side == \"call\" else scenario_returns[\"bull\"]\n",
    " )\n",
    " rr_multiple = (max(directional_return, 0.0) + 1e-9) / (\n",
    " abs(min(adverse_return, 0.0)) + 1e-9\n",
    " )\n",
    "\n",
    " prob_profit = compute_prob_profit(side, spot, strike, premium, iv, dte)\n",
    " pop_score = np.clip(safe_float(prob_profit, 0.0) * 100, 0, 100)\n",
    "\n",
    " breakeven = strike + premium if side == \"call\" else strike - premium\n",
    " breakeven_move_pct = (\n",
    " (breakeven - spot) / spot if side == \"call\" else (spot - breakeven) / spot\n",
    " )\n",
    "\n",
    " hv_30 = safe_float(feature_row.get(\"hv_30\"), np.nan)\n",
    " iv_hv_ratio = iv / hv_30 if not np.isnan(hv_30) and hv_30 > 0 else np.nan\n",
    " iv_score = iv_value_score(\n",
    " iv,\n",
    " hv_30,\n",
    " safe_float(feature_row.get(\"iv_rank_proxy\"), np.nan),\n",
    " safe_float(feature_row.get(\"iv_percentile_proxy\"), np.nan),\n",
    " )\n",
    "\n",
    " alignment = (\n",
    " safe_float(feature_row.get(\"bull_signal\"), 0.5) * 100\n",
    " if side == \"call\"\n",
    " else safe_float(feature_row.get(\"bear_signal\"), 0.5) * 100\n",
    " )\n",
    " conviction = (\n",
    " safe_float(feature_row.get(\"conviction_bull\"), 50.0)\n",
    " if side == \"call\"\n",
    " else safe_float(feature_row.get(\"conviction_bear\"), 50.0)\n",
    " )\n",
    "\n",
    " liq_score = liquidity_score(\n",
    " safe_float(option_row.get(\"openInterest\"), 0.0),\n",
    " safe_float(option_row.get(\"volume\"), 0.0),\n",
    " safe_float(option_row.get(\"spread_pct\"), np.nan),\n",
    " )\n",
    "\n",
    " components = {\n",
    " \"iv_value\": iv_score,\n",
    " \"expected\": expected_return_score(expected_return),\n",
    " \"rr\": rr_score(rr_multiple),\n",
    " \"pop\": pop_score,\n",
    " \"alignment\": np.clip(alignment, 0, 100),\n",
    " \"liquidity\": liq_score,\n",
    " \"conviction\": np.clip(conviction, 0, 100),\n",
    " }\n",
    "\n",
    " master_score = weighted_average(components, HORIZON_SCORE_WEIGHTS[horizon])\n",
    " iv_profit_blend = 0.45 * components[\"iv_value\"] + 0.55 * components[\"expected\"]\n",
    "\n",
    " intrinsic = max(spot - strike, 0) if side == \"call\" else max(strike - spot, 0)\n",
    " extrinsic = premium - intrinsic\n",
    "\n",
    " return {\n",
    " \"ticker\": option_row.get(\"ticker\"),\n",
    " \"sector\": feature_row.get(\"sector\"),\n",
    " \"industry\": feature_row.get(\"industry\"),\n",
    " \"side\": side,\n",
    " \"horizon\": horizon,\n",
    " \"expiration\": option_row.get(\"expiration\"),\n",
    " \"dte\": dte,\n",
    " \"contract_symbol\": option_row.get(\"contractSymbol\"),\n",
    " \"spot\": spot,\n",
    " \"strike\": strike,\n",
    " \"moneyness\": safe_float(option_row.get(\"moneyness\"), np.nan),\n",
    " \"mid\": premium,\n",
    " \"bid\": safe_float(option_row.get(\"bid\"), np.nan),\n",
    " \"ask\": safe_float(option_row.get(\"ask\"), np.nan),\n",
    " \"spread_pct\": safe_float(option_row.get(\"spread_pct\"), np.nan),\n",
    " \"open_interest\": safe_float(option_row.get(\"openInterest\"), np.nan),\n",
    " \"volume\": safe_float(option_row.get(\"volume\"), np.nan),\n",
    " \"iv\": iv,\n",
    " \"hv_30\": hv_30,\n",
    " \"iv_hv_ratio\": iv_hv_ratio,\n",
    " \"iv_rank_proxy\": safe_float(feature_row.get(\"iv_rank_proxy\"), np.nan),\n",
    " \"iv_percentile_proxy\": safe_float(\n",
    " feature_row.get(\"iv_percentile_proxy\"), np.nan\n",
    " ),\n",
    " \"breakeven\": breakeven,\n",
    " \"breakeven_move_pct\": breakeven_move_pct,\n",
    " \"intrinsic\": intrinsic,\n",
    " \"extrinsic\": extrinsic,\n",
    " \"extrinsic_pct\": extrinsic / premium if premium > 0 else np.nan,\n",
    " \"prob_profit\": prob_profit,\n",
    " \"expected_return\": expected_return,\n",
    " \"bull_return\": scenario_returns[\"bull\"],\n",
    " \"base_return\": scenario_returns[\"base\"],\n",
    " \"bear_return\": scenario_returns[\"bear\"],\n",
    " \"rr_multiple\": rr_multiple,\n",
    " \"directional_return\": directional_return,\n",
    " \"adverse_return\": adverse_return,\n",
    " \"alignment_score\": components[\"alignment\"],\n",
    " \"conviction_score\": components[\"conviction\"],\n",
    " \"iv_value_score\": components[\"iv_value\"],\n",
    " \"expected_score\": components[\"expected\"],\n",
    " \"rr_score\": components[\"rr\"],\n",
    " \"pop_score\": components[\"pop\"],\n",
    " \"liquidity_score\": components[\"liquidity\"],\n",
    " \"iv_profit_blend\": iv_profit_blend,\n",
    " \"master_score\": master_score,\n",
    " \"value_score\": feature_row.get(\"value_score\"),\n",
    " \"bull_signal\": feature_row.get(\"bull_signal\"),\n",
    " \"bear_signal\": feature_row.get(\"bear_signal\"),\n",
    " \"ret_1m\": feature_row.get(\"ret_1m\"),\n",
    " \"ret_3m\": feature_row.get(\"ret_3m\"),\n",
    " \"rsi_14\": feature_row.get(\"rsi_14\"),\n",
    " \"beta\": feature_row.get(\"beta\"),\n",
    " }\n",
    "\n",
    "\n",
    "def filter_chain_for_side_horizon(\n",
    " df: pd.DataFrame, side: str, horizon: str\n",
    ") -> pd.DataFrame:\n",
    " if df.empty:\n",
    " return df\n",
    "\n",
    " cfg = OPTION_SIDE_CONFIG[side][horizon]\n",
    " out = df.copy()\n",
    " out = out[\n",
    " (out[\"moneyness\"] >= cfg[\"min_moneyness\"])\n",
    " & (out[\"moneyness\"] <= cfg[\"max_moneyness\"])\n",
    " ]\n",
    " out = out[\n",
    " out[\"mid\"].notna() & (out[\"mid\"] >= MIN_PREMIUM) & (out[\"mid\"] <= MAX_PREMIUM)\n",
    " ]\n",
    "\n",
    " if LIQUIDITY_FILTER:\n",
    " out = out[out[\"openInterest\"].fillna(0) >= MIN_OPEN_INTEREST]\n",
    " out = out[out[\"volume\"].fillna(0) >= MIN_VOLUME]\n",
    " out = out[(out[\"spread_pct\"].isna()) | (out[\"spread_pct\"] <= MAX_SPREAD_PCT)]\n",
    "\n",
    " if out.empty:\n",
    " return out\n",
    "\n",
    " return out.sort_values([\"openInterest\", \"volume\"], ascending=False).head(\n",
    " MAX_CONTRACTS_PER_EXP\n",
    " )\n",
    "\n",
    "\n",
    "def build_candidates_for_ticker(ticker: str, feature_row: dict) -> List[dict]:\n",
    " spot = safe_float(feature_row.get(\"spot\"), np.nan)\n",
    " if np.isnan(spot) or spot <= 0:\n",
    " return []\n",
    "\n",
    " expirations = get_expirations(ticker)\n",
    " if not expirations:\n",
    " return []\n",
    "\n",
    " rows = []\n",
    " for horizon in HORIZONS:\n",
    " exp_list = pick_horizon_expirations(expirations, horizon)\n",
    " if not exp_list:\n",
    " continue\n",
    "\n",
    " for exp_date, _ in exp_list:\n",
    " calls, puts = fetch_chain(ticker, exp_date, spot)\n",
    "\n",
    " for side, chain_df in [(\"call\", calls), (\"put\", puts)]:\n",
    " if chain_df.empty:\n",
    " continue\n",
    "\n",
    " filtered = filter_chain_for_side_horizon(chain_df, side, horizon)\n",
    " if filtered.empty:\n",
    " continue\n",
    "\n",
    " for _, option_row in filtered.iterrows():\n",
    " result = evaluate_option_candidate(\n",
    " option_row, side, horizon, feature_row\n",
    " )\n",
    " if result:\n",
    " rows.append(result)\n",
    " return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477fee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SCREEN:\n",
    " tickers = screen_for_candidates(**SCREEN_PARAMS)\n",
    "else:\n",
    " tickers = []\n",
    "\n",
    "if TICKER_OVERRIDE:\n",
    " tickers = TICKER_OVERRIDE\n",
    "\n",
    "if CONVICTION_TICKERS:\n",
    " prepend = [t for t in CONVICTION_TICKERS if t not in tickers]\n",
    " tickers = prepend + tickers\n",
    "\n",
    "tickers = [t for t in tickers if t and isinstance(t, str)]\n",
    "if MAX_TICKERS:\n",
    " tickers = tickers[:MAX_TICKERS]\n",
    "\n",
    "print(f\"Tickers queued: {len(tickers)}\")\n",
    "if tickers:\n",
    " print(\", \".join(tickers[:25]))\n",
    "\n",
    "underlying_rows = []\n",
    "for i, ticker in enumerate(tickers, start=1):\n",
    " try:\n",
    " row = compute_underlying_features(ticker)\n",
    " if row:\n",
    " underlying_rows.append(row)\n",
    " print(f\"[{i:02d}/{len(tickers):02d}] {ticker}: {'ok' if row else 'skip'}\")\n",
    " except Exception as exc:\n",
    " print(f\"[{i:02d}/{len(tickers):02d}] {ticker}: error ({exc})\")\n",
    "\n",
    "underlying_df = pd.DataFrame(underlying_rows)\n",
    "if underlying_df.empty:\n",
    " raise RuntimeError(\n",
    " \"No underlying names survived feature preparation. Adjust screen constraints.\"\n",
    " )\n",
    "\n",
    "underlying_df[\"seed_score\"] = (\n",
    " 0.35 * underlying_df[\"conviction_bull\"].fillna(50)\n",
    " + 0.25 * underlying_df[\"value_score\"].fillna(50)\n",
    " + 0.20 * (100 - underlying_df[\"iv_rank_proxy\"].fillna(50))\n",
    " + 0.20 * (100 - (underlying_df[\"rsi_14\"].fillna(50) - 50).abs() * 2)\n",
    ")\n",
    "underlying_df = underlying_df.sort_values(\"seed_score\", ascending=False).reset_index(\n",
    " drop=True\n",
    ")\n",
    "\n",
    "display(\n",
    " underlying_df[\n",
    " [\n",
    " \"ticker\",\n",
    " \"sector\",\n",
    " \"spot\",\n",
    " \"seed_score\",\n",
    " \"conviction_bull\",\n",
    " \"conviction_bear\",\n",
    " \"value_score\",\n",
    " \"iv_rank_proxy\",\n",
    " \"iv_percentile_proxy\",\n",
    " \"ret_1m\",\n",
    " \"ret_3m\",\n",
    " \"hv_30\",\n",
    " ]\n",
    " ].head(25)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5671c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_rows = []\n",
    "selected_tickers = underlying_df[\"ticker\"].tolist()\n",
    "\n",
    "for i, ticker in enumerate(selected_tickers, start=1):\n",
    " feature_row = underlying_df[underlying_df[\"ticker\"] == ticker].iloc[0].to_dict()\n",
    " try:\n",
    " rows = build_candidates_for_ticker(ticker, feature_row)\n",
    " candidate_rows.extend(rows)\n",
    " print(f\"[{i:02d}/{len(selected_tickers):02d}] {ticker}: {len(rows)} candidates\")\n",
    " except Exception as exc:\n",
    " print(f\"[{i:02d}/{len(selected_tickers):02d}] {ticker}: error ({exc})\")\n",
    "\n",
    "candidates_df = pd.DataFrame(candidate_rows)\n",
    "if candidates_df.empty:\n",
    " raise RuntimeError(\"No option candidates found. Relax moneyness/liquidity filters.\")\n",
    "\n",
    "candidates_df[\"iv_rank_bucket\"] = candidates_df.groupby([\"side\", \"horizon\"])[\n",
    " \"iv_value_score\"\n",
    "].rank(method=\"min\", ascending=False)\n",
    "candidates_df[\"profit_rank_bucket\"] = candidates_df.groupby([\"side\", \"horizon\"])[\n",
    " \"expected_return\"\n",
    "].rank(method=\"min\", ascending=False)\n",
    "candidates_df[\"master_rank_bucket\"] = candidates_df.groupby([\"side\", \"horizon\"])[\n",
    " \"master_score\"\n",
    "].rank(method=\"min\", ascending=False)\n",
    "\n",
    "iv_pct = candidates_df.groupby([\"side\", \"horizon\"])[\"iv_value_score\"].transform(\n",
    " lambda s: pct_rank(s, higher_better=True)\n",
    ")\n",
    "profit_pct = candidates_df.groupby([\"side\", \"horizon\"])[\"expected_return\"].transform(\n",
    " lambda s: pct_rank(s, higher_better=True)\n",
    ")\n",
    "candidates_df[\"alpha_percentile\"] = 100 * (0.45 * iv_pct + 0.55 * profit_pct)\n",
    "\n",
    "candidates_df[\"master_grade\"] = pd.cut(\n",
    " candidates_df[\"master_score\"],\n",
    " bins=[-np.inf, 50, 60, 70, 80, 90, np.inf],\n",
    " labels=[\"F\", \"D\", \"C\", \"B\", \"A\", \"A+\"],\n",
    ")\n",
    "\n",
    "candidates_df[\"quality_gate\"] = (\n",
    " (candidates_df[\"iv_value_score\"] >= 30)\n",
    " & (candidates_df[\"liquidity_score\"] >= 35)\n",
    " & (candidates_df[\"prob_profit\"].fillna(0) >= 0.10)\n",
    " & (candidates_df[\"expected_return\"] > -0.60)\n",
    ")\n",
    "\n",
    "eligible_df = candidates_df[candidates_df[\"quality_gate\"]].copy()\n",
    "if eligible_df.empty:\n",
    " print(\"Quality gate removed all candidates. Falling back to full candidate set.\")\n",
    " eligible_df = candidates_df.copy()\n",
    "else:\n",
    " print(f\"Eligible after quality gate: {len(eligible_df)} / {len(candidates_df)}\")\n",
    "\n",
    "eligible_df[\"iv_rank_bucket\"] = eligible_df.groupby([\"side\", \"horizon\"])[\n",
    " \"iv_value_score\"\n",
    "].rank(method=\"min\", ascending=False)\n",
    "eligible_df[\"profit_rank_bucket\"] = eligible_df.groupby([\"side\", \"horizon\"])[\n",
    " \"expected_return\"\n",
    "].rank(method=\"min\", ascending=False)\n",
    "eligible_df[\"master_rank_bucket\"] = eligible_df.groupby([\"side\", \"horizon\"])[\n",
    " \"master_score\"\n",
    "].rank(method=\"min\", ascending=False)\n",
    "\n",
    "iv_pct_e = eligible_df.groupby([\"side\", \"horizon\"])[\"iv_value_score\"].transform(\n",
    " lambda s: pct_rank(s, higher_better=True)\n",
    ")\n",
    "profit_pct_e = eligible_df.groupby([\"side\", \"horizon\"])[\"expected_return\"].transform(\n",
    " lambda s: pct_rank(s, higher_better=True)\n",
    ")\n",
    "eligible_df[\"alpha_percentile\"] = 100 * (0.45 * iv_pct_e + 0.55 * profit_pct_e)\n",
    "\n",
    "print(f\"Total candidates: {len(candidates_df)}\")\n",
    "print(\"By side/horizon:\")\n",
    "print(candidates_df.groupby([\"side\", \"horizon\"]).size().to_string())\n",
    "print(\"Eligible side/horizon:\")\n",
    "print(eligible_df.groupby([\"side\", \"horizon\"]).size().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best contract per ticker/side/horizon\n",
    "best_tsh = (\n",
    " eligible_df.sort_values(\"master_score\", ascending=False)\n",
    " .groupby([\"ticker\", \"side\", \"horizon\"], as_index=False)\n",
    " .first()\n",
    ")\n",
    "\n",
    "best_tsh = best_tsh.sort_values(\n",
    " [\"side\", \"horizon\", \"master_score\"], ascending=[True, True, False]\n",
    ")\n",
    "\n",
    "display(\n",
    " best_tsh[\n",
    " [\n",
    " \"ticker\",\n",
    " \"side\",\n",
    " \"horizon\",\n",
    " \"expiration\",\n",
    " \"dte\",\n",
    " \"strike\",\n",
    " \"mid\",\n",
    " \"iv\",\n",
    " \"iv_hv_ratio\",\n",
    " \"prob_profit\",\n",
    " \"expected_return\",\n",
    " \"rr_multiple\",\n",
    " \"iv_value_score\",\n",
    " \"master_score\",\n",
    " \"master_rank_bucket\",\n",
    " ]\n",
    " ].head(40)\n",
    ")\n",
    "\n",
    "# Trifecta ideas: names that have one quality setup across all 3 horizons for the same side\n",
    "trifecta_input = best_tsh.copy()\n",
    "trifecta_counts = (\n",
    " trifecta_input.groupby([\"ticker\", \"side\"])[\"horizon\"]\n",
    " .nunique()\n",
    " .reset_index(name=\"horizon_count\")\n",
    ")\n",
    "complete = trifecta_counts[trifecta_counts[\"horizon_count\"] == 3][[\"ticker\", \"side\"]]\n",
    "\n",
    "trifecta_rows = []\n",
    "for _, row in complete.iterrows():\n",
    " tkr = row[\"ticker\"]\n",
    " side = row[\"side\"]\n",
    " sub = trifecta_input[\n",
    " (trifecta_input[\"ticker\"] == tkr) & (trifecta_input[\"side\"] == side)\n",
    " ]\n",
    " sub = sub.set_index(\"horizon\")\n",
    "\n",
    " weighted_master = 0.0\n",
    " weighted_expected = 0.0\n",
    " weighted_iv = 0.0\n",
    " for hz, w in TRIFECTA_WEIGHTS.items():\n",
    " weighted_master += safe_float(sub.loc[hz, \"master_score\"], 0.0) * w\n",
    " weighted_expected += safe_float(sub.loc[hz, \"expected_return\"], 0.0) * w\n",
    " weighted_iv += safe_float(sub.loc[hz, \"iv_value_score\"], 0.0) * w\n",
    "\n",
    " consistency = float(sub[\"master_score\"].min())\n",
    " trifecta_score = 0.55 * weighted_master + 0.25 * consistency + 0.20 * weighted_iv\n",
    "\n",
    " trifecta_rows.append(\n",
    " {\n",
    " \"ticker\": tkr,\n",
    " \"side\": side,\n",
    " \"sector\": sub[\"sector\"].dropna().iloc[0]\n",
    " if sub[\"sector\"].notna().any()\n",
    " else None,\n",
    " \"trifecta_score\": trifecta_score,\n",
    " \"weighted_master\": weighted_master,\n",
    " \"weighted_expected_return\": weighted_expected,\n",
    " \"weighted_iv_value\": weighted_iv,\n",
    " \"consistency_floor\": consistency,\n",
    " \"short_contract\": sub.loc[\"short\", \"contract_symbol\"],\n",
    " \"medium_contract\": sub.loc[\"medium\", \"contract_symbol\"],\n",
    " \"leaps_contract\": sub.loc[\"leaps\", \"contract_symbol\"],\n",
    " \"short_score\": safe_float(sub.loc[\"short\", \"master_score\"], np.nan),\n",
    " \"medium_score\": safe_float(sub.loc[\"medium\", \"master_score\"], np.nan),\n",
    " \"leaps_score\": safe_float(sub.loc[\"leaps\", \"master_score\"], np.nan),\n",
    " }\n",
    " )\n",
    "\n",
    "trifecta_df = pd.DataFrame(trifecta_rows).sort_values(\"trifecta_score\", ascending=False)\n",
    "\n",
    "if trifecta_df.empty:\n",
    " display(Markdown(\"No full 3-horizon trifecta ideas found in this run.\"))\n",
    "else:\n",
    " display(trifecta_df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d367b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board-style leaderboards: top ideas per side and horizon\n",
    "leaderboard_rows = []\n",
    "\n",
    "for side in [\"call\", \"put\"]:\n",
    " for horizon in [\"short\", \"medium\", \"leaps\"]:\n",
    " bucket = eligible_df[\n",
    " (eligible_df[\"side\"] == side) & (eligible_df[\"horizon\"] == horizon)\n",
    " ].copy()\n",
    " if bucket.empty:\n",
    " continue\n",
    "\n",
    " bucket = bucket.sort_values(\n",
    " [\"master_score\", \"alpha_percentile\", \"expected_return\"],\n",
    " ascending=False,\n",
    " ).head(TOP_PER_BUCKET)\n",
    " bucket[\"bucket_label\"] = f\"{side.upper()} | {horizon.upper()}\"\n",
    " leaderboard_rows.append(bucket)\n",
    "\n",
    "leaderboard_df = (\n",
    " pd.concat(leaderboard_rows, ignore_index=True)\n",
    " if leaderboard_rows\n",
    " else pd.DataFrame()\n",
    ")\n",
    "if leaderboard_df.empty:\n",
    " display(Markdown(\"No leaderboard rows generated.\"))\n",
    "else:\n",
    " display(\n",
    " leaderboard_df[\n",
    " [\n",
    " \"bucket_label\",\n",
    " \"ticker\",\n",
    " \"contract_symbol\",\n",
    " \"expiration\",\n",
    " \"dte\",\n",
    " \"spot\",\n",
    " \"strike\",\n",
    " \"mid\",\n",
    " \"iv\",\n",
    " \"iv_hv_ratio\",\n",
    " \"prob_profit\",\n",
    " \"expected_return\",\n",
    " \"rr_multiple\",\n",
    " \"iv_value_score\",\n",
    " \"alpha_percentile\",\n",
    " \"master_score\",\n",
    " \"master_grade\",\n",
    " ]\n",
    " ]\n",
    " )\n",
    "\n",
    "# Optional visual map of opportunities\n",
    "if not eligible_df.empty:\n",
    " plot_df = eligible_df.copy()\n",
    " fig = px.scatter(\n",
    " plot_df,\n",
    " x=\"iv_value_score\",\n",
    " y=\"expected_return\",\n",
    " color=\"master_score\",\n",
    " facet_row=\"side\",\n",
    " facet_col=\"horizon\",\n",
    " hover_data=[\n",
    " \"ticker\",\n",
    " \"contract_symbol\",\n",
    " \"dte\",\n",
    " \"mid\",\n",
    " \"prob_profit\",\n",
    " \"rr_multiple\",\n",
    " ],\n",
    " title=\"Opportunity Map: IV Value vs Expected Return\",\n",
    " color_continuous_scale=\"Viridis\",\n",
    " height=850,\n",
    " )\n",
    " fig.update_layout(margin=dict(l=20, r=20, t=60, b=20))\n",
    " fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════════\n",
    "#  Correlation and Beta-Weighted Diversification\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "#\n",
    "#  The leaderboard ranks contracts independently. This cell asks:\n",
    "#     \"If I own SEVERAL of these, am I actually diversified?\"\n",
    "#\n",
    "#  Steps:\n",
    "#    1. Fetch SPY + all underlying tickers' daily returns.\n",
    "#    2. Pairwise correlation matrix  →  heatmap.\n",
    "#    3. Beta-to-SPY for every name  →  normalised exposure.\n",
    "#    4. Diversification score:  penalise highly correlated pairs,\n",
    "#       reward names that add uncorrelated return.\n",
    "#    5. Greedy portfolio builder:  pick best-scored options while\n",
    "#       minimising portfolio correlation and balancing beta exposure.\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "\n",
    "display(Markdown(\"---\\n# Correlation and Beta-Weighted Portfolio\"))\n",
    "\n",
    "# ── 1. Collect daily returns for every ticker in the leaderboard ──\n",
    "\n",
    "# All unique tickers that made it to the leaderboard\n",
    "lb_tickers = (\n",
    " sorted(leaderboard_df[\"ticker\"].unique().tolist())\n",
    " if not leaderboard_df.empty\n",
    " else []\n",
    ")\n",
    "if not lb_tickers:\n",
    " lb_tickers = sorted(eligible_df[\"ticker\"].unique().tolist())\n",
    "\n",
    "# Always include SPY as the beta reference\n",
    "BENCHMARK = \"SPY\"\n",
    "fetch_list = [BENCHMARK] + [t for t in lb_tickers if t != BENCHMARK]\n",
    "\n",
    "returns_dict = {}\n",
    "print(f\"Fetching {len(fetch_list)} tickers for correlation matrix…\")\n",
    "for tkr in fetch_list:\n",
    " try:\n",
    " h = yf.Ticker(tkr).history(period=HISTORY_PERIOD)\n",
    " time.sleep(RATE_LIMIT_SLEEP * 0.5) # lighter sleep, just returns\n",
    " if h is not None and not h.empty and \"Close\" in h.columns:\n",
    " c = h[\"Close\"].dropna()\n",
    " if len(c) >= 60:\n",
    " returns_dict[tkr] = np.log(c / c.shift(1)).dropna()\n",
    " except Exception:\n",
    " pass\n",
    "\n",
    "print(f\" Got return series for {len(returns_dict)} tickers\")\n",
    "\n",
    "# Build a common-date returns matrix\n",
    "returns_matrix = pd.DataFrame(returns_dict).dropna()\n",
    "if BENCHMARK not in returns_matrix.columns:\n",
    " display(\n",
    " Markdown(\n",
    " \"> Could not fetch SPY — beta-weighting will use β from yfinance info.\"\n",
    " )\n",
    " )\n",
    "\n",
    "# ── 2. Pairwise correlation matrix ──\n",
    "\n",
    "stock_tickers = [c for c in returns_matrix.columns if c != BENCHMARK]\n",
    "if len(stock_tickers) >= 2:\n",
    " corr_matrix = returns_matrix[stock_tickers].corr()\n",
    "\n",
    "    # Avg off-diagonal correlation\n",
    " mask_upper = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    " avg_corr = corr_matrix.where(mask_upper).stack().mean()\n",
    "\n",
    " display(Markdown(f\"### Pairwise Correlation ({len(stock_tickers)} names)\"))\n",
    " display(\n",
    " Markdown(\n",
    " f\"> **Average pairwise ρ = {avg_corr:.2f}** — \"\n",
    " f\"{'🟢 Well diversified' if avg_corr < 0.40 else '🟡 Moderate overlap' if avg_corr < 0.60 else '🔴 Highly correlated'}\"\n",
    " )\n",
    " )\n",
    "\n",
    "    # Heatmap\n",
    " fig_corr = go.Figure(\n",
    " data=go.Heatmap(\n",
    " z=corr_matrix.values,\n",
    " x=corr_matrix.columns.tolist(),\n",
    " y=corr_matrix.index.tolist(),\n",
    " colorscale=\"RdBu_r\",\n",
    " zmid=0,\n",
    " zmin=-1,\n",
    " zmax=1,\n",
    " text=corr_matrix.round(2).values.tolist(),\n",
    " texttemplate=\"%{text}\",\n",
    " textfont=dict(size=10),\n",
    " )\n",
    " )\n",
    " fig_corr.update_layout(\n",
    " title=\"Underlying Pairwise Correlation (log returns)\",\n",
    " height=max(400, 50 * len(stock_tickers)),\n",
    " width=max(500, 55 * len(stock_tickers)),\n",
    " margin=dict(l=20, r=20, t=50, b=20),\n",
    " )\n",
    " fig_corr.show()\n",
    "else:\n",
    " corr_matrix = pd.DataFrame()\n",
    " avg_corr = np.nan\n",
    " display(Markdown(\"> Only 1 ticker — correlation analysis requires ≥ 2 names.\"))\n",
    "\n",
    "# ── 3. Beta-to-SPY for every name ──\n",
    "\n",
    "display(Markdown(\"### Beta-Weighted Exposure (SPY-normalised)\"))\n",
    "\n",
    "beta_rows = []\n",
    "spy_var = (\n",
    " returns_matrix[BENCHMARK].var() if BENCHMARK in returns_matrix.columns else None\n",
    ")\n",
    "\n",
    "for tkr in stock_tickers:\n",
    " if tkr not in returns_matrix.columns:\n",
    " continue\n",
    "\n",
    "    # Regression beta = Cov(stock, SPY) / Var(SPY)\n",
    " if spy_var and spy_var > 0:\n",
    " cov = returns_matrix[[tkr, BENCHMARK]].cov().iloc[0, 1]\n",
    " reg_beta = cov / spy_var\n",
    " else:\n",
    " reg_beta = np.nan\n",
    "\n",
    "    # Fallback: yfinance .info beta\n",
    " yf_beta = np.nan\n",
    " if tkr in underlying_df[\"ticker\"].values:\n",
    " yf_beta = safe_float(\n",
    " underlying_df.loc[underlying_df[\"ticker\"] == tkr, \"beta\"].iloc[0], np.nan\n",
    " )\n",
    "\n",
    " best_beta = reg_beta if not np.isnan(reg_beta) else yf_beta\n",
    "\n",
    "    # Annualised vol\n",
    " ann_vol = (\n",
    " float(returns_matrix[tkr].std() * math.sqrt(252))\n",
    " if tkr in returns_matrix.columns\n",
    " else np.nan\n",
    " )\n",
    "\n",
    "    # Correlation to SPY\n",
    " corr_spy = (\n",
    " float(returns_matrix[[tkr, BENCHMARK]].corr().iloc[0, 1])\n",
    " if BENCHMARK in returns_matrix.columns\n",
    " else np.nan\n",
    " )\n",
    "\n",
    " beta_rows.append(\n",
    " {\n",
    " \"Ticker\": tkr,\n",
    " \"Reg β (SPY)\": round(best_beta, 2) if not np.isnan(best_beta) else np.nan,\n",
    " \"yf β\": round(yf_beta, 2) if not np.isnan(yf_beta) else np.nan,\n",
    " \"Ann Vol\": round(ann_vol * 100, 1) if not np.isnan(ann_vol) else np.nan,\n",
    " \"ρ(SPY)\": round(corr_spy, 2) if not np.isnan(corr_spy) else np.nan,\n",
    " }\n",
    " )\n",
    "\n",
    "beta_df = pd.DataFrame(beta_rows)\n",
    "if not beta_df.empty:\n",
    " beta_df = beta_df.sort_values(\"Reg β (SPY)\", ascending=False)\n",
    " display(\n",
    " beta_df.style.background_gradient(\n",
    " subset=[\"Reg β (SPY)\"], cmap=\"RdYlGn_r\", vmin=0.5, vmax=2.0\n",
    " )\n",
    " .background_gradient(subset=[\"ρ(SPY)\"], cmap=\"RdYlGn_r\", vmin=0, vmax=1.0)\n",
    " .format({\"Ann Vol\": \"{:.1f}%\"}, na_rep=\"—\")\n",
    " .set_caption(\"Regression β + volatility + SPY correlation\")\n",
    " )\n",
    "else:\n",
    " display(Markdown(\"> No beta data available.\"))\n",
    "\n",
    "# Build a lookup for the builder\n",
    "beta_lookup = {\n",
    " r[\"Ticker\"]: r[\"Reg β (SPY)\"] for r in beta_rows if not np.isnan(r[\"Reg β (SPY)\"])\n",
    "}\n",
    "\n",
    "# ── 4. Diversification score  ──\n",
    "#\n",
    "#  For each option in the leaderboard, compute a \"diversification bonus\"\n",
    "#  that is HIGH when the underlying has LOW average correlation to the\n",
    "#  other top names.  This gets blended into a \"diversified_score\".\n",
    "\n",
    "display(Markdown(\"### Diversification-Adjusted Scores\"))\n",
    "\n",
    "div_source = (\n",
    " leaderboard_df.copy() if not leaderboard_df.empty else eligible_df.head(60).copy()\n",
    ")\n",
    "\n",
    "if not corr_matrix.empty and len(corr_matrix) >= 2:\n",
    "    # Average correlation of each ticker to all OTHER tickers\n",
    " avg_corr_per_ticker = {}\n",
    " for tkr in corr_matrix.columns:\n",
    " others = corr_matrix.loc[tkr].drop(tkr, errors=\"ignore\")\n",
    " avg_corr_per_ticker[tkr] = others.mean() if len(others) > 0 else 0.5\n",
    "\n",
    "    # Diversification bonus:  100 * (1 - avg_corr)  → high when low correlation\n",
    " div_source[\"avg_corr_to_peers\"] = (\n",
    " div_source[\"ticker\"].map(avg_corr_per_ticker).fillna(0.5)\n",
    " )\n",
    " div_source[\"diversification_bonus\"] = (1 - div_source[\"avg_corr_to_peers\"]) * 100\n",
    "\n",
    "    # Beta penalty: prefer β near 1.0 (balanced exposure)\n",
    " div_source[\"beta_for_calc\"] = (\n",
    " div_source[\"ticker\"].map(beta_lookup).fillna(div_source[\"beta\"].fillna(1.0))\n",
    " )\n",
    " div_source[\"beta_penalty\"] = div_source[\"beta_for_calc\"].apply(\n",
    " lambda b: max(0, 100 - 40 * abs(b - 1.0)) if not np.isnan(b) else 50\n",
    " )\n",
    "\n",
    "    # Diversified score = 60% master_score + 20% diversification_bonus + 20% beta_balance\n",
    " div_source[\"diversified_score\"] = (\n",
    " 0.60 * div_source[\"master_score\"]\n",
    " + 0.20 * div_source[\"diversification_bonus\"]\n",
    " + 0.20 * div_source[\"beta_penalty\"]\n",
    " )\n",
    "else:\n",
    " div_source[\"avg_corr_to_peers\"] = np.nan\n",
    " div_source[\"diversification_bonus\"] = 0\n",
    " div_source[\"beta_for_calc\"] = div_source[\"beta\"].fillna(1.0)\n",
    " div_source[\"beta_penalty\"] = 50\n",
    " div_source[\"diversified_score\"] = div_source[\"master_score\"]\n",
    "\n",
    "div_source = div_source.sort_values(\"diversified_score\", ascending=False)\n",
    "\n",
    "disp_cols = [\n",
    " \"ticker\",\n",
    " \"side\",\n",
    " \"horizon\",\n",
    " \"strike\",\n",
    " \"dte\",\n",
    " \"mid\",\n",
    " \"iv\",\n",
    " \"master_score\",\n",
    " \"avg_corr_to_peers\",\n",
    " \"diversification_bonus\",\n",
    " \"beta_for_calc\",\n",
    " \"diversified_score\",\n",
    "]\n",
    "disp_cols = [c for c in disp_cols if c in div_source.columns]\n",
    "display(\n",
    " div_source[disp_cols]\n",
    " .head(20)\n",
    " .style.format(\n",
    " {\n",
    " \"mid\": \"${:.2f}\",\n",
    " \"iv\": \"{:.1%}\",\n",
    " \"master_score\": \"{:.1f}\",\n",
    " \"avg_corr_to_peers\": \"{:.2f}\",\n",
    " \"diversification_bonus\": \"{:.1f}\",\n",
    " \"beta_for_calc\": \"{:.2f}\",\n",
    " \"diversified_score\": \"{:.1f}\",\n",
    " },\n",
    " na_rep=\"—\",\n",
    " )\n",
    " .background_gradient(subset=[\"diversified_score\"], cmap=\"YlGn\")\n",
    " .background_gradient(subset=[\"avg_corr_to_peers\"], cmap=\"RdYlGn_r\", vmin=0, vmax=1)\n",
    " .set_caption(\"Top 20 — Diversification-adjusted ranking\")\n",
    ")\n",
    "\n",
    "# ── 5. Greedy diversified portfolio builder ──\n",
    "#\n",
    "#  Pick the highest diversified_score option, then iteratively add\n",
    "#  the next-best option whose underlying has LOW correlation to\n",
    "#  everything already in the portfolio.\n",
    "#\n",
    "#  Constraint: max one option per ticker per side.\n",
    "\n",
    "display(Markdown(\"### Diversified Portfolio — Greedy Builder\"))\n",
    "\n",
    "MAX_PORTFOLIO_POSITIONS = int(os.getenv(\"MAX_PORTFOLIO_POSITIONS\", \"8\"))\n",
    "MAX_PORTFOLIO_CORR = float(os.getenv(\"MAX_PORTFOLIO_CORR\", \"0.65\"))\n",
    "PORTFOLIO_BUDGET = float(os.getenv(\"PORTFOLIO_BUDGET\", \"15000\"))\n",
    "DIVERSIFIED_SIDES = [\"call\"] # change to [\"call\", \"put\"] to include puts\n",
    "\n",
    "pool = div_source[div_source[\"side\"].isin(DIVERSIFIED_SIDES)].copy()\n",
    "\n",
    "# Keep only the best option per ticker (highest diversified_score)\n",
    "pool = pool.sort_values(\"diversified_score\", ascending=False)\n",
    "pool = pool.drop_duplicates(subset=[\"ticker\", \"side\"], keep=\"first\")\n",
    "\n",
    "portfolio_picks = []\n",
    "portfolio_tickers = set()\n",
    "budget_remaining = PORTFOLIO_BUDGET\n",
    "\n",
    "for _, row in pool.iterrows():\n",
    " if len(portfolio_picks) >= MAX_PORTFOLIO_POSITIONS:\n",
    " break\n",
    "\n",
    " tkr = row[\"ticker\"]\n",
    " cost_per_contract = row[\"mid\"] * 100\n",
    " if cost_per_contract <= 0 or cost_per_contract > budget_remaining:\n",
    " continue\n",
    "\n",
    "    # Check correlation to existing portfolio members\n",
    " if portfolio_tickers and not corr_matrix.empty and tkr in corr_matrix.columns:\n",
    " max_corr_to_port = max(\n",
    " abs(corr_matrix.loc[tkr, pt]) if pt in corr_matrix.columns else 0.0\n",
    " for pt in portfolio_tickers\n",
    " )\n",
    " if max_corr_to_port > MAX_PORTFOLIO_CORR:\n",
    " continue # too correlated with something already held\n",
    "\n",
    " portfolio_picks.append(row)\n",
    " portfolio_tickers.add(tkr)\n",
    " budget_remaining -= cost_per_contract\n",
    "\n",
    "if portfolio_picks:\n",
    " port_df = pd.DataFrame(portfolio_picks)\n",
    "\n",
    "    # Beta-weighted SPY-equivalent delta\n",
    " port_df[\"spy_eq_delta\"] = port_df[\"beta_for_calc\"] * port_df[\"mid\"] * 100\n",
    "\n",
    "    # Portfolio-level stats\n",
    " total_cost = (port_df[\"mid\"] * 100).sum()\n",
    " total_spy_delta = port_df[\"spy_eq_delta\"].sum()\n",
    " weighted_beta = (\n",
    " (port_df[\"beta_for_calc\"] * port_df[\"mid\"] * 100).sum() / total_cost\n",
    " if total_cost > 0\n",
    " else np.nan\n",
    " )\n",
    "\n",
    "    # Correlation among portfolio members\n",
    " port_tkrs = port_df[\"ticker\"].tolist()\n",
    " if len(port_tkrs) >= 2 and not corr_matrix.empty:\n",
    " port_corr = corr_matrix.loc[\n",
    " [t for t in port_tkrs if t in corr_matrix.index],\n",
    " [t for t in port_tkrs if t in corr_matrix.columns],\n",
    " ]\n",
    " mask_u = np.triu(np.ones_like(port_corr, dtype=bool), k=1)\n",
    " port_avg_corr = port_corr.where(mask_u).stack().mean()\n",
    " else:\n",
    " port_avg_corr = np.nan\n",
    "\n",
    " display(\n",
    " Markdown(f\"\"\"\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Positions** | {len(port_df)} across {len(port_df[\"ticker\"].unique())} tickers |\n",
    "| **Total cost** | ${total_cost:,.0f} of ${PORTFOLIO_BUDGET:,.0f} budget |\n",
    "| **SPY-eq Δ$** | ${total_spy_delta:,.0f} |\n",
    "| **Weighted β** | {weighted_beta:.2f} |\n",
    "| **Portfolio avg ρ** | {port_avg_corr:.2f} — {\"🟢 Low\" if port_avg_corr < 0.35 else \"🟡 Moderate\" if port_avg_corr < 0.55 else \"🔴 High\"} |\n",
    "| **Max pairwise ρ allowed** | {MAX_PORTFOLIO_CORR} |\n",
    "\"\"\")\n",
    " )\n",
    "\n",
    " port_disp = [\n",
    " \"ticker\",\n",
    " \"side\",\n",
    " \"horizon\",\n",
    " \"expiration\",\n",
    " \"dte\",\n",
    " \"strike\",\n",
    " \"mid\",\n",
    " \"iv\",\n",
    " \"master_score\",\n",
    " \"diversified_score\",\n",
    " \"beta_for_calc\",\n",
    " \"spy_eq_delta\",\n",
    " \"avg_corr_to_peers\",\n",
    " ]\n",
    " port_disp = [c for c in port_disp if c in port_df.columns]\n",
    " display(\n",
    " port_df[port_disp]\n",
    " .style.format(\n",
    " {\n",
    " \"mid\": \"${:.2f}\",\n",
    " \"iv\": \"{:.1%}\",\n",
    " \"master_score\": \"{:.1f}\",\n",
    " \"diversified_score\": \"{:.1f}\",\n",
    " \"beta_for_calc\": \"{:.2f}\",\n",
    " \"spy_eq_delta\": \"${:,.0f}\",\n",
    " \"avg_corr_to_peers\": \"{:.2f}\",\n",
    " },\n",
    " na_rep=\"—\",\n",
    " )\n",
    " .background_gradient(subset=[\"diversified_score\"], cmap=\"YlGn\")\n",
    " .set_caption(\"Diversified portfolio — correlation-constrained picks\")\n",
    " )\n",
    "\n",
    "    # ── Beta-weighted exposure chart ──\n",
    " fig_beta = go.Figure()\n",
    " fig_beta.add_trace(\n",
    " go.Bar(\n",
    " x=port_df[\"ticker\"],\n",
    " y=port_df[\"spy_eq_delta\"],\n",
    " marker_color=port_df[\"beta_for_calc\"].apply(\n",
    " lambda b: (\n",
    " \"#2ecc71\"\n",
    " if 0.8 <= b <= 1.2\n",
    " else \"#f39c12\"\n",
    " if b < 0.8\n",
    " else \"#e74c3c\"\n",
    " )\n",
    " ),\n",
    " text=port_df[\"beta_for_calc\"].apply(lambda b: f\"β={b:.2f}\"),\n",
    " textposition=\"outside\",\n",
    " )\n",
    " )\n",
    " fig_beta.add_hline(\n",
    " y=total_spy_delta / len(port_df),\n",
    " line_dash=\"dash\",\n",
    " annotation_text=f\"Equal share = ${total_spy_delta / len(port_df):,.0f}\",\n",
    " )\n",
    " fig_beta.update_layout(\n",
    " title=\"Beta-Weighted SPY-Equivalent Exposure ($)\",\n",
    " xaxis_title=\"Ticker\",\n",
    " yaxis_title=\"SPY-Eq Δ$ (β × premium × 100)\",\n",
    " height=420,\n",
    " margin=dict(l=20, r=20, t=50, b=20),\n",
    " )\n",
    " fig_beta.show()\n",
    "\n",
    "    # ── Portfolio correlation mini-heatmap ──\n",
    " if len(port_tkrs) >= 2 and not corr_matrix.empty:\n",
    " port_corr_clean = corr_matrix.loc[\n",
    " [t for t in port_tkrs if t in corr_matrix.index],\n",
    " [t for t in port_tkrs if t in corr_matrix.columns],\n",
    " ]\n",
    " fig_pcorr = go.Figure(\n",
    " data=go.Heatmap(\n",
    " z=port_corr_clean.values,\n",
    " x=port_corr_clean.columns.tolist(),\n",
    " y=port_corr_clean.index.tolist(),\n",
    " colorscale=\"RdBu_r\",\n",
    " zmid=0,\n",
    " zmin=-1,\n",
    " zmax=1,\n",
    " text=port_corr_clean.round(2).values.tolist(),\n",
    " texttemplate=\"%{text}\",\n",
    " )\n",
    " )\n",
    " fig_pcorr.update_layout(\n",
    " title=\"Portfolio Members — Pairwise Correlation\",\n",
    " height=350,\n",
    " width=max(400, 70 * len(port_tkrs)),\n",
    " margin=dict(l=20, r=20, t=50, b=20),\n",
    " )\n",
    " fig_pcorr.show()\n",
    "\n",
    "else:\n",
    " port_df = pd.DataFrame()\n",
    " display(\n",
    " Markdown(\n",
    " \"> No positions could be built within the budget and correlation constraints.\"\n",
    " )\n",
    " )\n",
    "\n",
    "# Save for export\n",
    "diversified_df = div_source.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export artifacts for repeatable workflows\n",
    "base = f\"{OUTPUT_DIR}/master_bto_{RUN_STAMP}\"\n",
    "\n",
    "underlying_path = f\"{base}_underlyings.csv\"\n",
    "candidates_path = f\"{base}_candidates.csv\"\n",
    "eligible_path = f\"{base}_eligible_candidates.csv\"\n",
    "best_path = f\"{base}_best_per_ticker_side_horizon.csv\"\n",
    "leaderboard_path = f\"{base}_leaderboard.csv\"\n",
    "trifecta_path = f\"{base}_trifecta.csv\"\n",
    "\n",
    "diversified_path = f\"{base}_diversified_scores.csv\"\n",
    "portfolio_path = f\"{base}_diversified_portfolio.csv\"\n",
    "correlation_path = f\"{base}_correlation_matrix.csv\"\n",
    "\n",
    "underlying_df.to_csv(underlying_path, index=False)\n",
    "candidates_df.to_csv(candidates_path, index=False)\n",
    "eligible_df.to_csv(eligible_path, index=False)\n",
    "best_tsh.to_csv(best_path, index=False)\n",
    "leaderboard_df.to_csv(leaderboard_path, index=False)\n",
    "if \"trifecta_df\" in globals() and isinstance(trifecta_df, pd.DataFrame):\n",
    "    trifecta_df.to_csv(trifecta_path, index=False)\n",
    "if (\n",
    "    \"diversified_df\" in globals()\n",
    "    and isinstance(diversified_df, pd.DataFrame)\n",
    "    and not diversified_df.empty\n",
    "):\n",
    "    diversified_df.to_csv(diversified_path, index=False)\n",
    "if \"port_df\" in globals() and isinstance(port_df, pd.DataFrame) and not port_df.empty:\n",
    "    port_df.to_csv(portfolio_path, index=False)\n",
    "if (\n",
    "    \"corr_matrix\" in globals()\n",
    "    and isinstance(corr_matrix, pd.DataFrame)\n",
    "    and not corr_matrix.empty\n",
    "):\n",
    "    corr_matrix.to_csv(correlation_path)\n",
    "\n",
    "print(\"Saved files:\")\n",
    "print(\" -\", underlying_path)\n",
    "print(\" -\", candidates_path)\n",
    "print(\" -\", eligible_path)\n",
    "print(\" -\", best_path)\n",
    "print(\" -\", leaderboard_path)\n",
    "if \"trifecta_df\" in globals() and isinstance(trifecta_df, pd.DataFrame):\n",
    "    print(\" -\", trifecta_path)\n",
    "if (\n",
    "    \"diversified_df\" in globals()\n",
    "    and isinstance(diversified_df, pd.DataFrame)\n",
    "    and not diversified_df.empty\n",
    "):\n",
    "    print(\" -\", diversified_path)\n",
    "if \"port_df\" in globals() and isinstance(port_df, pd.DataFrame) and not port_df.empty:\n",
    "    print(\" -\", portfolio_path)\n",
    "if (\n",
    "    \"corr_matrix\" in globals()\n",
    "    and isinstance(corr_matrix, pd.DataFrame)\n",
    "    and not corr_matrix.empty\n",
    "):\n",
    "    print(\" -\", correlation_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
